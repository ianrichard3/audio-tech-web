This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
.env.example
.github/workflows/main.yml
.gitignore
alembic.ini
alembic/env.py
alembic/versions/001_create_schema.py
app/__init__.py
app/api/__init__.py
app/api/deps.py
app/api/routes/__init__.py
app/api/routes/devices.py
app/api/routes/ports.py
app/api/routes/state.py
app/core/__init__.py
app/core/config.py
app/db/__init__.py
app/db/base.py
app/db/session.py
app/main.py
app/models/__init__.py
app/models/device.py
app/models/patchbay_point.py
app/models/port.py
app/schemas/__init__.py
app/schemas/device.py
app/schemas/health.py
app/schemas/patchbay.py
app/schemas/port.py
app/schemas/state.py
app/services/__init__.py
app/services/devices.py
app/services/ports.py
app/services/state.py
ARCHITECTURE.md
docker-compose.yml
Dockerfile
entrypoint.sh
README.md
requirements.txt

================================================================
Files
================================================================

================
File: .github/workflows/main.yml
================
name: CD - Deploy

on:
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    env:
      REMOTE_PATH: ${{ secrets.REMOTE_PATH }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Preparar clave SSH
        run: |
          mkdir -p ~/.ssh
          echo "$PI_SSH_PRIVATE_KEY" > key.pem
          chmod 600 key.pem
        env:
          PI_SSH_PRIVATE_KEY: ${{ secrets.PI_SSH_PRIVATE_KEY }}

      - name: Pull y desplegar con Docker Compose en el VPS
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem -p "$PI_SSH_PORT" "$PI_USER@$PI_HOST" \
                "REMOTE_PATH='${REMOTE_PATH}' bash -s" <<'EOF'
          set -e
          echo "Conectado al VPS"
          cd "$REMOTE_PATH"
          echo "Directorio actual de trabajo: $(pwd)"

          echo "Haciendo git pull..."
          git pull origin main

          echo "Deteniendo contenedores..."
          docker compose down || true

          echo "Levantando con build..."
          docker compose up -d --build

          echo "Limpieza de imágenes no utilizadas..."
          docker image prune -f || true

          echo "✅ Despliegue completado."
          EOF

        env:
          PI_HOST: ${{ secrets.PI_HOST }}
          PI_USER: ${{ secrets.PI_USER }}
          PI_SSH_PORT: ${{ secrets.PI_SSH_PORT }}
          REMOTE_PATH: ${{ env.REMOTE_PATH }}

      - name: Limpiar clave local
        if: always()
        run: rm -f key.pem

================
File: .gitignore
================
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[codz]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#   Usually these files are written by a python script from a template
#   before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py.cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
# Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
# uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
# poetry.lock
# poetry.toml

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.
#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control
# pdm.lock
# pdm.toml
.pdm-python
.pdm-build/

# pixi
#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.
# pixi.lock
#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one
#   in the .venv directory. It is recommended not to include this directory in version control.
.pixi

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# Redis
*.rdb
*.aof
*.pid

# RabbitMQ
mnesia/
rabbitmq/
rabbitmq-data/

# ActiveMQ
activemq-data/

# SageMath parsed files
*.sage.py

# Environments
.env
.envrc
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#   JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#   be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#   and can be added to the global gitignore or merged into this file.  For a more nuclear
#   option (not recommended) you can uncomment the following to ignore the entire idea folder.
# .idea/

# Abstra
#   Abstra is an AI-powered process automation framework.
#   Ignore directories containing user credentials, local state, and settings.
#   Learn more at https://abstra.io/docs
.abstra/

# Visual Studio Code
#   Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore 
#   that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore
#   and can be added to the global gitignore or merged into this file. However, if you prefer, 
#   you could uncomment the following to ignore the entire vscode folder
# .vscode/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

# Marimo
marimo/_static/
marimo/_lsp/
__marimo__/

# Streamlit
.streamlit/secrets.toml

================
File: alembic/env.py
================
from logging.config import fileConfig

from sqlalchemy import engine_from_config, pool
from alembic import context

from app.core.config import settings
from app.db.base import Base
from app import models  # noqa: F401

config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

config.set_main_option("sqlalchemy.url", settings.database_url)

target_metadata = Base.metadata


def run_migrations_offline() -> None:
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(connection=connection, target_metadata=target_metadata)

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()

================
File: app/__init__.py
================


================
File: app/api/__init__.py
================


================
File: app/api/deps.py
================
from typing import Generator
from app.db.session import SessionLocal


def get_db() -> Generator:
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

================
File: app/api/routes/__init__.py
================
from app.api.routes.state import router as state
from app.api.routes.devices import router as devices
from app.api.routes.ports import router as ports

__all__ = ["state", "devices", "ports"]

================
File: app/core/__init__.py
================


================
File: app/core/config.py
================
from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic import Field
from typing import List


class Settings(BaseSettings):
    model_config = SettingsConfigDict(env_file=".env", env_file_encoding="utf-8")

    database_url: str = Field(..., alias="DATABASE_URL")
    cors_origins: List[str] = Field(default_factory=list, alias="CORS_ORIGINS")
    app_name: str = "Pepper API"


settings = Settings()

================
File: app/db/__init__.py
================


================
File: app/db/base.py
================
from sqlalchemy.orm import declarative_base


Base = declarative_base()

================
File: app/db/session.py
================
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from app.core.config import settings


engine = create_engine(settings.database_url, pool_pre_ping=True)
SessionLocal = sessionmaker(bind=engine, autocommit=False, autoflush=False)

================
File: app/models/__init__.py
================
from app.models.device import Device
from app.models.port import Port
from app.models.patchbay_point import PatchbayPoint

__all__ = ["Device", "Port", "PatchbayPoint"]

================
File: app/models/device.py
================
from sqlalchemy import Column, Integer, String, DateTime, func
from sqlalchemy.orm import relationship

from app.db.base import Base


class Device(Base):
    __tablename__ = "devices"

    id = Column(Integer, primary_key=True)
    name = Column(String, nullable=False)
    type = Column(String, nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    ports = relationship(
        "Port",
        back_populates="device",
        cascade="all, delete-orphan",
        order_by="Port.id",
    )

================
File: app/models/patchbay_point.py
================
from sqlalchemy import Column, Integer, String, Text, DateTime, func
from sqlalchemy.orm import relationship

from app.db.base import Base


class PatchbayPoint(Base):
    __tablename__ = "patchbay_points"

    id = Column(Integer, primary_key=True)
    name = Column(String, nullable=False)
    description = Column(Text, nullable=False, server_default="")
    type = Column(String, nullable=False, server_default="standard")
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    ports = relationship("Port", back_populates="patchbay_point")

================
File: app/schemas/__init__.py
================


================
File: app/schemas/health.py
================
from pydantic import BaseModel, ConfigDict, Field


class HealthResponse(BaseModel):
    status: str = Field(
        ..., 
        description="Service health status.",
        examples=["ok"],
    )

    model_config = ConfigDict(
        json_schema_extra={
            "examples": [
                {"status": "ok"}
            ]
        }
    )

================
File: app/services/__init__.py
================


================
File: app/services/ports.py
================
from sqlalchemy import select
from sqlalchemy.orm import Session
from sqlalchemy.exc import IntegrityError

from app.models.port import Port


class PatchbayConflictError(Exception):
    pass


def link_port(db: Session, port_id: str, patchbay_id: int) -> tuple[Port, str | None]:
    old_port = db.execute(
        select(Port).where(Port.patchbay_id == patchbay_id)
    ).scalar_one_or_none()

    if old_port:
        old_port.patchbay_id = None

    port = db.execute(select(Port).where(Port.id == port_id)).scalar_one_or_none()
    if not port:
        raise ValueError("Port not found")

    port.patchbay_id = patchbay_id

    try:
        db.commit()
    except IntegrityError as exc:
        db.rollback()
        raise PatchbayConflictError("Patchbay point already linked") from exc

    return port, old_port.id if old_port else None


def update_port_patchbay(db: Session, port_id: str, patchbay_id: int | None) -> Port:
    port = db.execute(select(Port).where(Port.id == port_id)).scalar_one_or_none()
    if not port:
        raise ValueError("Port not found")

    port.patchbay_id = patchbay_id

    try:
        db.commit()
    except IntegrityError as exc:
        db.rollback()
        raise PatchbayConflictError("Patchbay point already linked") from exc

    return port


def unlink_port(db: Session, port_id: str) -> Port:
    port = db.execute(select(Port).where(Port.id == port_id)).scalar_one_or_none()
    if not port:
        raise ValueError("Port not found")

    port.patchbay_id = None
    db.commit()
    return port

================
File: app/services/state.py
================
from sqlalchemy.orm import Session, joinedload
from sqlalchemy import select

from app.models.device import Device
from app.models.patchbay_point import PatchbayPoint


def get_state(db: Session):
    patchbay_stmt = select(PatchbayPoint).order_by(PatchbayPoint.id)
    patchbay_points = db.execute(patchbay_stmt).scalars().all()

    devices_stmt = (
        select(Device)
        .options(joinedload(Device.ports))
        .order_by(Device.id)
    )
    devices = db.execute(devices_stmt).scalars().unique().all()

    return {
        "patchbay_points": patchbay_points,
        "devices": devices,
    }

================
File: ARCHITECTURE.md
================
# Architecture

## Overview
This backend replaces Supabase RPCs with a self-hosted Postgres database and a FastAPI service. The API preserves the existing data model and behaviors, while enforcing critical rules at the database level for correctness under concurrency.

## Goals
- Replace Supabase DB + RPC functions with Postgres + FastAPI.
- Preserve behavior for devices, ports, and patchbay points.
- Keep the API contract stable (now in snake_case) to minimize client friction.
- Enforce data invariants in the database as well as in transaction logic.

## Non-Goals
- No UI changes in this backend repo.
- No auth added by default.
- No additional features outside current RPC behavior.

## Tech Stack
- FastAPI for HTTP API and automatic Swagger/Redoc docs.
- SQLAlchemy 2.0 ORM for database access.
- Alembic for schema migrations.
- Postgres 16 as the database.
- Docker Compose for local orchestration.

## High-Level Architecture
- `app/main.py` initializes the FastAPI app, health endpoint, and routers.
- `app/api/routes/*` defines HTTP endpoints.
- `app/services/*` holds transaction logic and business rules.
- `app/models/*` defines ORM models and DB constraints.
- `app/schemas/*` defines Pydantic request/response shapes (snake_case).
- `alembic/` manages database migrations.

## Data Model
Tables:
- `devices`: id, name, type, created_at
- `ports`: id, device_id, label, type, patchbay_id, created_at
- `patchbay_points`: id, name, description, type, created_at

Key constraints:
- `ports.device_id` references `devices.id` with `ON DELETE CASCADE`.
- `ports.patchbay_id` references `patchbay_points.id`.
- `UNIQUE (ports.patchbay_id)` ensures one patchbay point is used by at most one port at a time.
- `patchbay_points.description` is `NOT NULL DEFAULT ''`.
- `ports.type` is a Postgres ENUM `port_type` with values `Input`, `Output`, `Other`.

## API Contract (snake_case)
Endpoints:
- `GET /state`
  - Returns all patchbay points and devices with ports.
- `POST /devices`
  - Creates a device and its ports atomically.
- `DELETE /devices/{device_id}`
  - Deletes device; ports are deleted via cascade.
- `POST /ports/{port_id}/link`
  - Links a port to a patchbay point, unlinks any existing port, returns `unlinked_port_id`.
- `PUT /ports/{port_id}/patchbay`
  - Directly sets `patchbay_id` (or null).
- `POST /ports/{port_id}/unlink`
  - Sets `patchbay_id` to null.
- `GET /health`
  - Simple health response.

Swagger UI is available at `/docs`, and Redoc at `/redoc`.

## Business Rules Preserved
- Create device + ports happens in a single transaction.
- Port IDs are deterministic: `dev-{device_id}-port-{index}`.
- One patchbay point can be occupied by only one port (unique constraint).
- Linking a port to a patchbay point automatically unlinks any existing port.
- Deleting a device cascades to its ports.

## Migration Strategy
- Alembic manages schema changes.
- The initial migration creates tables, constraints, and enum types.
- Entry point runs `alembic upgrade head` on container start.

## Docker and Runtime
- `docker-compose.yml` defines:
  - `db`: Postgres 16 with volume persistence.
  - `api`: FastAPI service.
  - `pgadmin`: pgAdmin UI on port 5050.
- `entrypoint.sh` applies migrations before running the API.

## Configuration
Environment variables are defined in `.env.example`:
- `DATABASE_URL` for SQLAlchemy.
- `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB` for the DB.
- `CORS_ORIGINS` (JSON list string).
- `PGADMIN_DEFAULT_EMAIL`, `PGADMIN_DEFAULT_PASSWORD` for pgAdmin.

## Error Handling
- 404 for missing device/port.
- 409 for patchbay uniqueness conflicts.
- 422 for validation errors (FastAPI/Pydantic).

## Future Considerations
- Add auth (API key or JWT) if exposed outside a trusted network.
- Add rate limiting and stricter CORS for production.
- Add structured logging and request IDs if needed.
- Add automated tests for transaction behavior and DB constraints.

================
File: Dockerfile
================
FROM python:3.11-slim

WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY app ./app
COPY alembic ./alembic
COPY alembic.ini ./alembic.ini
COPY entrypoint.sh ./entrypoint.sh
RUN chmod +x /app/entrypoint.sh

ENTRYPOINT ["/app/entrypoint.sh"]
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

================
File: entrypoint.sh
================
#!/usr/bin/env sh
set -e

alembic upgrade head
exec "$@"

================
File: requirements.txt
================
fastapi==0.111.0
uvicorn[standard]==0.30.1
SQLAlchemy==2.0.31
psycopg[binary]==3.1.19
alembic==1.13.2
pydantic-settings==2.3.4

================
File: .env.example
================
POSTGRES_USER=pepper
POSTGRES_PASSWORD=pepper
POSTGRES_DB=pepper
DATABASE_URL=postgresql+psycopg://pepper:pepper@db:5432/pepper
CORS_ORIGINS=["http://localhost:5173","http://localhost:8000"]
PGADMIN_DEFAULT_EMAIL=admin@pepper.com
PGADMIN_DEFAULT_PASSWORD=admin

================
File: alembic.ini
================
[alembic]
script_location = alembic
prepend_sys_path = .

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s

================
File: alembic/versions/001_create_schema.py
================
"""create core schema

Revision ID: 001_create_schema
Revises: 
Create Date: 2026-01-13 00:00:00.000000
"""

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql


revision = "001_create_schema"
down_revision = None
branch_labels = None
depends_on = None


# NOTE:
# We create the enum explicitly with checkfirst=True, and we disable SQLAlchemy's
# automatic CREATE TYPE during table creation to avoid DuplicateObject.
port_type = postgresql.ENUM("Input", "Output", "Other", name="port_type", create_type=False)


def upgrade() -> None:
    port_type.create(op.get_bind(), checkfirst=True)

    op.create_table(
        "devices",
        sa.Column("id", sa.Integer(), primary_key=True),
        sa.Column("name", sa.String(), nullable=False),
        sa.Column("type", sa.String(), nullable=False),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()")),
    )

    op.create_table(
        "patchbay_points",
        sa.Column("id", sa.Integer(), primary_key=True),
        sa.Column("name", sa.String(), nullable=False),
        sa.Column("description", sa.Text(), nullable=False, server_default=""),
        sa.Column("type", sa.String(), nullable=False, server_default="standard"),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()")),
    )

    op.create_table(
        "ports",
        sa.Column("id", sa.String(), primary_key=True),
        sa.Column("device_id", sa.Integer(), nullable=False),
        sa.Column("label", sa.String(), nullable=False),
        sa.Column("type", port_type, nullable=False),
        sa.Column("patchbay_id", sa.Integer(), nullable=True),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()")),
        sa.ForeignKeyConstraint(["device_id"], ["devices.id"], ondelete="CASCADE"),
        sa.ForeignKeyConstraint(["patchbay_id"], ["patchbay_points.id"]),
        sa.UniqueConstraint("patchbay_id", name="uq_ports_patchbay_id"),
    )


def downgrade() -> None:
    op.drop_table("ports")
    op.drop_table("patchbay_points")
    op.drop_table("devices")
    port_type.drop(op.get_bind(), checkfirst=True)

================
File: app/api/routes/devices.py
================
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session

from app.api.deps import get_db
from app.schemas.device import DeviceCreate, DeviceResponse, DeviceDeleteResponse
from app.services.devices import create_device, delete_device


router = APIRouter(tags=["Devices"])


@router.post(
    "/devices",
    response_model=DeviceResponse,
    status_code=status.HTTP_201_CREATED,
    summary="Create a device",
    description="Creates a device and its ports in a single request.",
)
def create_device_endpoint(payload: DeviceCreate, db: Session = Depends(get_db)):
    return create_device(db, payload)


@router.delete(
    "/devices/{device_id}",
    response_model=DeviceDeleteResponse,
    summary="Delete a device",
    description="Deletes a device by id. Ports are removed as well.",
    responses={
        404: {
            "description": "Not Found",
            "content": {
                "application/json": {
                    "examples": {
                        "not_found": {
                            "summary": "Device not found",
                            "value": {"detail": "Device not found"},
                        }
                    }
                }
            },
        }
    },
)
def delete_device_endpoint(device_id: int, db: Session = Depends(get_db)):
    try:
        return delete_device(db, device_id)
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(exc)) from exc

================
File: app/api/routes/ports.py
================
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session

from app.api.deps import get_db
from app.schemas.port import PortLinkRequest, PortPatchbayUpdateRequest, PortLinkResponse, PortResponse
from app.services.ports import link_port, unlink_port, update_port_patchbay, PatchbayConflictError


router = APIRouter(tags=["Ports"])


@router.post(
    "/ports/{port_id}/link",
    response_model=PortLinkResponse,
    summary="Link a port",
    description="Links the specified port to a target patchbay point.",
    responses={
        404: {
            "description": "Not Found",
            "content": {
                "application/json": {
                    "examples": {
                        "not_found": {
                            "summary": "Port not found",
                            "value": {"detail": "Port not found"},
                        }
                    }
                }
            },
        },
        409: {
            "description": "Conflict",
            "content": {
                "application/json": {
                    "examples": {
                        "patchbay_conflict": {
                            "summary": "Patchbay point already occupied",
                            "value": {"detail": "Patchbay point already occupied"},
                        }
                    }
                }
            },
        },
    },
)
def link_port_endpoint(port_id: str, payload: PortLinkRequest, db: Session = Depends(get_db)):
    try:
        port, unlinked_port_id = link_port(db, port_id, payload.patchbay_id)
        response = PortLinkResponse.model_validate(port)
        response.unlinked_port_id = unlinked_port_id
        return response
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(exc)) from exc
    except PatchbayConflictError as exc:
        raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=str(exc)) from exc


@router.put(
    "/ports/{port_id}/patchbay",
    response_model=PortResponse,
    summary="Update a port patchbay point",
    description="Assigns or clears the patchbay point for a port.",
    responses={
        404: {
            "description": "Not Found",
            "content": {
                "application/json": {
                    "examples": {
                        "not_found": {
                            "summary": "Port not found",
                            "value": {"detail": "Port not found"},
                        }
                    }
                }
            },
        },
        409: {
            "description": "Conflict",
            "content": {
                "application/json": {
                    "examples": {
                        "patchbay_conflict": {
                            "summary": "Patchbay point already occupied",
                            "value": {"detail": "Patchbay point already occupied"},
                        }
                    }
                }
            },
        },
    },
)
def update_port_patchbay_endpoint(port_id: str, payload: PortPatchbayUpdateRequest, db: Session = Depends(get_db)):
    try:
        return update_port_patchbay(db, port_id, payload.patchbay_id)
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(exc)) from exc
    except PatchbayConflictError as exc:
        raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=str(exc)) from exc


@router.post(
    "/ports/{port_id}/unlink",
    response_model=PortResponse,
    summary="Unlink a port",
    description="Removes the patchbay point assignment from a port.",
    responses={
        404: {
            "description": "Not Found",
            "content": {
                "application/json": {
                    "examples": {
                        "not_found": {
                            "summary": "Port not found",
                            "value": {"detail": "Port not found"},
                        }
                    }
                }
            },
        }
    },
)
def unlink_port_endpoint(port_id: str, db: Session = Depends(get_db)):
    try:
        return unlink_port(db, port_id)
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(exc)) from exc

================
File: app/api/routes/state.py
================
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session

from app.api.deps import get_db
from app.schemas.state import StateResponse
from app.services.state import get_state


router = APIRouter(tags=["State"])


@router.get(
    "/state",
    response_model=StateResponse,
    summary="Get current state",
    description="Returns the current patchbay points and devices with ports.",
)
def read_state(db: Session = Depends(get_db)):
    return get_state(db)

================
File: app/main.py
================
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from app.core.config import settings
from app.api.routes.state import router as state_router
from app.api.routes.devices import router as devices_router
from app.api.routes.ports import router as ports_router
from app.schemas.health import HealthResponse


openapi_tags = [
    {"name": "Health", "description": "Service status checks."},
    {"name": "State", "description": "Read the current system state."},
    {"name": "Devices", "description": "Create and delete devices (and their ports)."},
    {"name": "Ports", "description": "Link/unlink ports to patchbay points."},
]

app = FastAPI(title=settings.app_name, openapi_tags=openapi_tags)

if settings.cors_origins:
    app.add_middleware(
        CORSMiddleware,
        allow_origins=settings.cors_origins,
        allow_credentials=True,
        allow_methods=["*"] ,
        allow_headers=["*"],
    )


@app.get(
    "/health",
    response_model=HealthResponse,
    tags=["Health"],
    summary="Health check",
    description="Returns a simple health status payload.",
)
def health_check():
    return {"status": "ok"}


app.include_router(state_router)
app.include_router(devices_router)
app.include_router(ports_router)

================
File: app/models/port.py
================
import enum
from sqlalchemy import Column, String, Integer, DateTime, ForeignKey, func, Enum, UniqueConstraint
from sqlalchemy.orm import relationship

from app.db.base import Base


class PortType(str, enum.Enum):
    INPUT = "Input"
    OUTPUT = "Output"
    OTHER = "Other"


def _enum_values(enum_cls):
    return [member.value for member in enum_cls]


class Port(Base):
    __tablename__ = "ports"
    __table_args__ = (
        UniqueConstraint("patchbay_id", name="uq_ports_patchbay_id"),
    )

    id = Column(String, primary_key=True)
    device_id = Column(Integer, ForeignKey("devices.id", ondelete="CASCADE"), nullable=False)
    label = Column(String, nullable=False)
    type = Column(
        Enum(
            PortType,
            name="port_type",
            values_callable=_enum_values,
        ),
        nullable=False,
    )
    patchbay_id = Column(Integer, ForeignKey("patchbay_points.id"), nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    device = relationship("Device", back_populates="ports")
    patchbay_point = relationship("PatchbayPoint", back_populates="ports")

================
File: app/schemas/device.py
================
from pydantic import BaseModel, ConfigDict, Field
from typing import List

from app.schemas.port import PortCreate, PortResponse


class DeviceBase(BaseModel):
    name: str = Field(
        ...,
        description="Device display name.",
        examples=["Juno-106"],
    )
    type: str = Field(
        ...,
        description="Free-form device type/category.",
        examples=["synth"],
    )


class DeviceCreate(DeviceBase):
    ports: List[PortCreate] = Field(
        ...,
        description="Ports to create along with the device.",
    )

    model_config = ConfigDict(
        json_schema_extra={
            "examples": [
                {
                    "name": "Juno-106",
                    "type": "synth",
                    "ports": [
                        {"label": "MIDI IN", "type": "Input", "patchbay_id": None},
                        {"label": "MIDI OUT", "type": "Output", "patchbay_id": None},
                    ],
                }
            ]
        }
    )


class DeviceResponse(DeviceBase):
    id: int
    ports: List[PortResponse]

    model_config = ConfigDict(
        from_attributes=True,
        json_schema_extra={
            "examples": [
                {
                    "id": 1,
                    "name": "Juno-106",
                    "type": "synth",
                    "ports": [
                        {"id": "dev-1-port-1", "label": "MIDI IN", "type": "Input", "patchbay_id": None},
                        {"id": "dev-1-port-2", "label": "MIDI OUT", "type": "Output", "patchbay_id": None},
                    ],
                }
            ]
        },
    )


class DeviceDeleteResponse(DeviceBase):
    id: int

    model_config = ConfigDict(
        from_attributes=True,
        json_schema_extra={
            "examples": [
                {"id": 1, "name": "Juno-106", "type": "synth"}
            ]
        },
    )

================
File: app/schemas/patchbay.py
================
from pydantic import BaseModel, ConfigDict, Field


class PatchbayPointResponse(BaseModel):
    id: int = Field(..., description="Patchbay point id.", examples=[1])
    name: str = Field(..., description="Patchbay point name.", examples=["PB-01"]) 
    description: str = Field(..., description="Description shown in UI.", examples=["Top row left"]) 
    type: str = Field(..., description="Free-form patchbay point type.", examples=["standard"]) 

    model_config = ConfigDict(
        from_attributes=True,
        json_schema_extra={
            "examples": [
                {"id": 1, "name": "PB-01", "description": "Top row left", "type": "standard"}
            ]
        },
    )

================
File: app/schemas/port.py
================
from pydantic import BaseModel, ConfigDict, Field, field_validator
from typing import Optional
from app.models.port import PortType


class PortBase(BaseModel):
    label: str = Field(
        ...,
        description="Human-friendly label for the port.",
        examples=["Port 1"],
    )
    type: PortType = Field(
        ...,
        description="Port type/direction.",
        examples=["Input"],
    )
    patchbay_id: Optional[int] = Field(
        default=None,
        description="Optional PatchbayPoint id this port is linked to.",
        examples=[1],
    )

    @field_validator("type", mode="before")
    @classmethod
    def coerce_port_type(cls, value):
        if isinstance(value, PortType):
            return value
        if isinstance(value, str):
            normalized = value.strip()
            for member in PortType:
                if normalized.lower() == str(member.value).lower():
                    return member
                if normalized.upper() == member.name:
                    return member
        return value


class PortCreate(PortBase):
    pass


class PortResponse(PortBase):
    id: str

    model_config = ConfigDict(
        from_attributes=True,
        json_schema_extra={
            "examples": [
                {
                    "id": "dev-1-port-1",
                    "label": "Port 1",
                    "type": "Input",
                    "patchbay_id": 1,
                }
            ]
        },
    )


class PortLinkResponse(PortResponse):
    unlinked_port_id: Optional[str] = None

    model_config = ConfigDict(
        from_attributes=True,
        json_schema_extra={
            "examples": [
                {
                    "id": "dev-1-port-1",
                    "label": "Port 1",
                    "type": "Input",
                    "patchbay_id": 1,
                    "unlinked_port_id": "dev-2-port-3",
                }
            ]
        },
    )


class PortLinkRequest(BaseModel):
    patchbay_id: int = Field(
        ...,
        description="PatchbayPoint id to link this port to.",
        examples=[1],
    )

    model_config = ConfigDict(
        json_schema_extra={
            "examples": [
                {"patchbay_id": 1}
            ]
        }
    )


class PortPatchbayUpdateRequest(BaseModel):
    patchbay_id: Optional[int] = Field(
        default=None,
        description="Set to a PatchbayPoint id to link, or null to unlink.",
        examples=[1, None],
    )

    model_config = ConfigDict(
        json_schema_extra={
            "examples": [
                {"patchbay_id": 1},
                {"patchbay_id": None},
            ]
        }
    )

================
File: app/schemas/state.py
================
from pydantic import BaseModel, ConfigDict, Field
from typing import List

from app.schemas.device import DeviceResponse
from app.schemas.patchbay import PatchbayPointResponse


class StateResponse(BaseModel):
    patchbay_points: List[PatchbayPointResponse] = Field(
        ...,
        description="All patchbay points.",
    )
    devices: List[DeviceResponse] = Field(
        ...,
        description="All devices with their ports.",
    )

    model_config = ConfigDict(
        json_schema_extra={
            "examples": [
                {
                    "patchbay_points": [
                        {"id": 1, "name": "PB-01", "description": "Top row left", "type": "standard"}
                    ],
                    "devices": [
                        {
                            "id": 1,
                            "name": "Juno-106",
                            "type": "synth",
                            "ports": [
                                {"id": "dev-1-port-1", "label": "MIDI IN", "type": "Input", "patchbay_id": 1}
                            ],
                        }
                    ],
                }
            ]
        }
    )

================
File: app/services/devices.py
================
from sqlalchemy.orm import Session, joinedload
from sqlalchemy import select

from app.models.device import Device
from app.models.port import Port
from app.schemas.device import DeviceCreate


def create_device(db: Session, payload: DeviceCreate) -> Device:
    device = Device(name=payload.name, type=payload.type)
    db.add(device)
    db.flush()

    ports = []
    for index, port in enumerate(payload.ports, start=1):
        port_id = f"dev-{device.id}-port-{index}"
        ports.append(
            Port(
                id=port_id,
                device_id=device.id,
                label=port.label,
                type=port.type,
                patchbay_id=port.patchbay_id,
            )
        )

    if ports:
        db.add_all(ports)

    db.commit()
    db.refresh(device)

    stmt = (
        select(Device)
        .options(joinedload(Device.ports))
        .where(Device.id == device.id)
    )
    return db.execute(stmt).unique().scalar_one()


def delete_device(db: Session, device_id: int) -> Device:
    stmt = select(Device).where(Device.id == device_id)
    device = db.execute(stmt).scalar_one_or_none()
    if not device:
        raise ValueError("Device not found")

    db.delete(device)
    db.commit()
    return device

================
File: README.md
================
# pepper-backend

## Local development

1) Copy env file

```bash
cp .env.example .env
```

2) Start services

```bash
docker compose up --build
```

## API

- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`
- Health: `http://localhost:8000/health`

================
File: docker-compose.yml
================
services:
  db:
    container_name: pepper-db
    image: postgres:16
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5435:5432"

  api:
    container_name: pepper-api
    build: .
    restart: unless-stopped
    environment:
      DATABASE_URL: ${DATABASE_URL}
      CORS_ORIGINS: ${CORS_ORIGINS}
    depends_on:
      - db
    ports:
      - "8088:8000"

  pgadmin:
    container_name: pepper-pgadmin
    image: dpage/pgadmin4:8
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL:-admin@pepper.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD:-admin}
    depends_on:
      - db
    ports:
      - "8090:80"

volumes:
  postgres_data:





================================================================
End of Codebase
================================================================
